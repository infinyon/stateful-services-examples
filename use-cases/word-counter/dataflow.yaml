apiVersion: 0.4.0
meta:
  name: word-counter
  version: 0.1.0
  namespace: examples

config:
  # Data format converter for reading & writing to topics.
  #   - json, raw
  converter: json

  # Consumers need to know where to start reading when the project is first started
  #   - {position: Begining, value: 0}
  #   - {position: End, value: 2}
  #   - {position: Offset, value: 23}
  consumer:
    default_starting_offset:
      value: 0
      position: End

types:
  # Schema for the input topic
  sentence:
    type: string

  # Schema for the aggregate logic and output topic
  word-count:
    type: object
    properties:
      word:
        type: string
      count:
        type: u32

  # Schema for the output topic
  top-words:
    type: list
    items:
      type: word-count

topics:
  # topic definitions, schema, add converters that are different from config.converter.
  sentence:
    name: sentence
    schema:
      value:
        type: string
        converter: raw
  most-used-words:
    name: most-used-words
    schema:
      value:
        type: top-words

services:
  # Service definition the input and output topics, and the transformations.
  word-processing-window:
    sources:
      - type: topic
        id: sentence
    states:
      - name: count-per-word
        type: keyed-state
        properties:
          key:
            type: string
          value:
            type: u32

    transforms:
      # Split the sentence into words
      - operator: flat-map
        run: |
          fn split_sequence(sentence: String) -> Result<Vec<String>, String> {
            Ok(sentence.split_whitespace().map(|word| word.chars().filter(|c| c.is_alphanumeric()).collect::<String>()).filter(|word| !word.is_empty()).collect())
          }
    window:
      tumbling:
        duration: 20s

      assign-timestamp:
        # Instruct the engine to apply the timestamp from the event metadata for the watermark operator
        run: |
          fn assign_event_timestamp(value: String, event_time: i64) -> Result<i64, String> {
            Ok(event_time)
          }

      partition:
        # Assign a partition key to divide the data set for the update operation
        assign-key:
          run: |
            fn assign_word_key(word: String) -> Result<String, String> {
              Ok(word.to_lowercase().chars().filter(|c| c.is_alphanumeric()).collect())
            }

        transforms:
          # Retrieve state by key and increment by 1.
          - operator: update-state
            run: |
              fn increment_word_count(word: String) -> Result<(), String> {
                count_per_word().increment(1);
                Ok(())
                }

      flush:
        # Read the full state and compute the top 3 words sorted by count.
        run: |
          fn compute_most_used_words() -> Result<TopWords, String> {
            let mut top3 = count_per_word().clone();
            top3.sort_by(|a, b| a.value.cmp(&b.value));
            top3.reverse();
            top3.truncate(3);
            Ok(top3.iter().map( | entry | WordCount { word: entry.key.clone(), count: entry.value }).collect())
          }

    sinks:
      - type: topic
        id: most-used-words
