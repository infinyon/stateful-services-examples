apiVersion: 0.1.0
meta:
  name: word-counter
  version: 0.1.0
  namespace: my-org

config:
  # Data format converter for reading & writing to topics.
  #   - json, raw
  converter: json

  # Consumers need to know where to start reading when the project is first started
  #   - {position: Begining, value: 0}
  #   - {position: End, value: 2}
  #   - {position: Offset, value: 23}
  consumer:
    default_starting_offset:
      value: 0 
      position: End

types:
  # Schema for the input topic
  sentence:
    type: string

  # Schema for the aggregate logic and output topic
  word-count:
    type: object
    properties:
      word:
        type: string
      count:
        type: u32

  # Schema for the output topic
  top-words:
    type: list
    items:
      type: word-count

topics:
  # topic definitions, schema, add converters that are different from config.converter.
  sentence:
    name: sentence
    schema:
      value:
        type: string
        converter: raw
  most-used-words:
    name: most-used-words
    schema:
      value:
        type: top-words

services:
  # Service definition the input and output topics, and the transformations.
  word-processing-window:
    source:
      type: topic
      id: sentence

    transforms:
      window:
        tumbling:
          duration: 20s

      states:
        - name: count-per-word
          type: keyed-state
          properties:
            key:
              type: string
            value:
              type: u32

      steps:
        # Split the sentence into words
        - operator: flat-map
          run: |
            fn split_sequence(sentence: String) -> Result<Vec<String>, String> {
              Ok(sentence.split_whitespace().map(String::from).collect())
            }            

        # Instruct the engine to apply the timestamp from the event metadata for the watermark operator
        - operator: assign-timestamp
          run: |
            fn assign_event_timestamp(value: String, event_time: i64) -> Result<i64, String> {
              Ok(event_time)
            }            

        # Assign a partition key to divide the data set for the update operation
        - operator: assign-key
          run: |
            fn assign_word_key(word: String) -> Result<String, String> {
              Ok(word.to_lowercase().chars().filter(|c| c.is_alphanumeric()).collect())
            }            

        # Retrieve state by key and increment by 1.
        - operator: update-state
          run: |
            fn increment_word_count(word: String) -> Result<(), String> {
              count_per_word().increment(1);
              Ok(())
              }            

      flush:
        # Read the full state and compute the top 3 words sorted by count.
        operator: aggregate
        run: |
          fn compute_most_used_words(count_per_word: CountPerWord) -> Result<TopWords, String> {
            let mut top3 = count_per_word;
            top3.sort_by(|a, b| a.value.cmp(&b.value));
            top3.reverse();
            top3.truncate(3);
            Ok(top3.iter().map( | entry | WordCount { word: entry.key.clone(), count: entry.value }).collect())
          }          

    sink:
      type: topic
      id: most-used-words
